{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyN0/HqwyIZBYlANXVp8Vcoy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports and configurations"],"metadata":{"id":"nRwlfYGNRiAc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwkbQ-fIRL68"},"outputs":[],"source":["import datetime\n","from math import sqrt\n","\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder, FunctionTransformer\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.feature_selection import SelectKBest, f_regression\n","\n","#  (high-level, simple to use)\n","import plotly.express as px\n","# (low-level, highly customizable)\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","\n","from scipy import stats\n","\n"]},{"cell_type":"code","source":["# Set Plotly as Pandas plotting backend\n","\n","pd.options.plotting.backend = \"plotly\"\n","np.set_printoptions(precision=2, suppress=True)\n","pd.options.display.precision = 2\n","pd.options.display.float_format = '{:.2f}'.format\n"],"metadata":{"id":"e8YiTxWdNV80"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Helper Funcitons"],"metadata":{"id":"HgbGcngfOwTE"}},{"cell_type":"code","source":["def plot_feature_target_scatter(df, features, target_variable):\n","    \"\"\"\n","    Displays a figure with multiple scatter plots showing the correlation\n","    between each feature and the target variable.\n","\n","    Args:\n","        df (pd.DataFrame): DataFrame containing features and target variable.\n","        features (list): List of column names to be considered as features.\n","        target_variable (str): Name of the target variable column.\n","    \"\"\"\n","\n","    num_features = len(features)\n","    if num_features == 0:\n","        print(\"No features provided to plot.\")\n","        return\n","\n","    # Determine subplot grid layout (adjust as needed for better layout)\n","    if num_features <= 2:\n","        rows = 1\n","        cols = num_features\n","    elif num_features <= 4:\n","        rows = 2\n","        cols = 2\n","    else:\n","        rows = (num_features + 1) // 3  # Adjust columns for more features\n","        cols = 3\n","\n","    fig = make_subplots(rows=rows, cols=cols,\n","                        subplot_titles=[f'Feature vs. Target: {feature}' for feature in features])\n","\n","    for i, feature in enumerate(features):\n","        row_index = (i // cols) + 1\n","        col_index = (i % cols) + 1\n","\n","        scatter_trace = go.Scatter(\n","            x=df[feature],\n","            y=df[target_variable],\n","            mode='markers',\n","            marker=dict(color='blue', size=5),\n","            name=feature\n","        )\n","        fig.add_trace(scatter_trace, row=row_index, col=col_index)\n","\n","        fig.update_xaxes(title_text=feature, row=row_index, col=col_index)\n","        fig.update_yaxes(title_text=target_variable, row=row_index, col=col_index)\n","\n","    fig.update_layout(title_text=\"Feature vs Target Variable Scatter Plots\", showlegend=False)\n","    fig.show()"],"metadata":{"id":"Iut54O3PO17T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load data"],"metadata":{"id":"vrigoF3iSGUg"}},{"cell_type":"code","source":["df = sns.load_dataset('diamonds')"],"metadata":{"id":"DIo_DKZhSFyi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EDA"],"metadata":{"id":"P0AiX-rBSSNv"}},{"cell_type":"markdown","source":["## Target variable"],"metadata":{"id":"YTVguxAFO_w6"}},{"cell_type":"code","source":["px.histogram(df, x='price', nbins=250)"],"metadata":{"id":"Vju4l8LqT9gM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["✅ **transforming target variable with log transformation might help**"],"metadata":{"id":"j23hP2kyUC_T"}},{"cell_type":"code","source":[],"metadata":{"id":"C_zn2y6iPG0r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Features vs target variable"],"metadata":{"id":"v4SHHHVOPCfx"}},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"re3vzr3gPKId"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_feature_target_scatter(df, df.select_dtypes('number').drop(columns='price').columns, 'price')"],"metadata":{"id":"5voAxnvsPMMX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["✅ **carat, x, y, z might require transformaitons**\n","\n","✅ **there are some very extreme outliers that might need to be removed**"],"metadata":{"id":"FqQS_dosPa7R"}},{"cell_type":"code","source":[],"metadata":{"id":"ltso72-RSofv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Plot transformations"],"metadata":{"id":"EIdtN-l6QDTp"}},{"cell_type":"code","source":["px.histogram(np.log(df['price']), nbins=250)"],"metadata":{"id":"8iIqJGulQG_W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformed, lambda_value = stats.boxcox(df['price'])\n","px.histogram(transformed, nbins=250)"],"metadata":{"id":"o5vGJ3gOQRHw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["px.histogram(df['price'] ** 0.5, nbins=250)"],"metadata":{"id":"MLyyPMisQtjp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["px.scatter(x=np.log1p(df['z']), y=np.log(df['price']))"],"metadata":{"id":"_PblDBZeQ7e0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["px.scatter(x=np.log(df['carat']), y=np.log(df['price']))"],"metadata":{"id":"gRba0z05Q_-L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Correlations"],"metadata":{"id":"Ihel-MluSXMM"}},{"cell_type":"code","source":["corr = pd.get_dummies(df, drop_first=True).select_dtypes(['number', 'bool']).corr()"],"metadata":{"id":"RVxMRr59SZzV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["px.imshow(corr, color_continuous_scale='Cividis')"],"metadata":{"id":"5J713Da2S35q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Plan\n","\n","- transformations for target and features\n","- categorical features - encoding required (one-hot / ordinal)\n","- feature selection\n","- outliers (that probably mean incorrect data, like zeros in x, y, z) - should be removed\n","- normalization\n","- splitting to multiple models\n","- other suggestions?"],"metadata":{"id":"RUrBybnSRZ_a"}},{"cell_type":"markdown","source":["# Advanced sklearn\n"],"metadata":{"id":"Uj1kC5tNTB6Z"}},{"cell_type":"markdown","source":["## Encoders"],"metadata":{"id":"EdlUdcGrmEeb"}},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder"],"metadata":{"id":"cvVHJjikTIWr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["one_hot_encoder =OneHotEncoder()"],"metadata":{"id":"hLoanb3DV8l1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[['color']]"],"metadata":{"id":"l3cvuvdGWa2w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["one_hot_encoder.fit(df[['color']])"],"metadata":{"id":"HzyGYEjjWLoP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformed = one_hot_encoder.transform(df[['color']]).toarray()"],"metadata":{"id":"03Z_prPPWPGI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformed"],"metadata":{"id":"Hm9NqWxAlzC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(transformed, columns=one_hot_encoder.get_feature_names_out())"],"metadata":{"id":"jrTk11penND7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Transformer"],"metadata":{"id":"AMueS3lDmGUz"}},{"cell_type":"code","source":["transformer = FunctionTransformer(np.log, validate=True)"],"metadata":{"id":"kv4uNl2vqzFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer.fit(df[['price']])"],"metadata":{"id":"faGp0JUXmMTn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer.transform(df[['price']])"],"metadata":{"id":"fTQoPQ6YmTEH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pipeline"],"metadata":{"id":"DEhWBhxLm2Cn"}},{"cell_type":"code","source":["pipe = Pipeline([\n","    ('log', FunctionTransformer(np.log1p, validate=True)),\n","    ('scaler', StandardScaler())\n","])"],"metadata":{"id":"ymuU--X9m5Pj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe.fit(df[['carat']])"],"metadata":{"id":"CE0oMmJdnBJs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe.transform(df[['carat']])"],"metadata":{"id":"i2yF3lopnH6w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Bringing all together with ColumnTransformer"],"metadata":{"id":"6uob8tpqnNTr"}},{"cell_type":"code","source":["# Define categorical and numerical features\n","categorical_features = ['cut', 'color', 'clarity']\n","numerical_features = ['carat', 'depth', 'table', 'x', 'y', 'z']\n","\n","# Define transformations for numerical features\n","num_transformers = ColumnTransformer(\n","    transformers=[\n","        ('xyz_transform', Pipeline([\n","            ('log', FunctionTransformer(np.log1p, validate=True)),\n","            ('scaler', StandardScaler())\n","        ]), ['x', 'y', 'z']),\n","        ('carat_scaler', Pipeline([\n","            ('log', FunctionTransformer(np.log, validate=True)),\n","            ('scaler', StandardScaler())\n","        ]), ['carat']),\n","        ('depth_transform', StandardScaler(), ['depth']),\n","        ('table_scaler', StandardScaler(), ['table']),\n","    ]\n",")\n","\n","\n","# Preprocessing pipeline\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', num_transformers, numerical_features),\n","        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n","    ]\n",")\n","\n","# Define model pipeline\n","pipeline = Pipeline([\n","    ('preprocessor', preprocessor),\n","    ('regressor', LinearRegression())\n","])\n","\n","# Split dataset\n","X = df.drop(columns=['price'])\n","# y = np.log1p(df['price'])  # Apply log transformation to target\n","y = np.log(df['price'])\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train model\n","pipeline.fit(X_train, y_train)\n","\n","# Predictions\n","y_pred = np.exp(pipeline.predict(X_test)) # Reverse log transformation\n","\n","\n","# Model evaluation\n","mse = mean_squared_error(np.exp(y_test), y_pred)  # Compare in original scale\n","r2 = r2_score(np.exp(y_test), y_pred)\n","mape = metrics.mean_absolute_percentage_error(np.exp(y_test), y_pred)\n","\n","### TRAIN\n","\n","# Predictions\n","y_pred_train = np.exp(pipeline.predict(X_train)) # Reverse log transformation\n","\n","\n","# Model evaluation\n","mse_train = mean_squared_error(np.exp(y_train), y_pred_train)  # Compare in original scale\n","r2_train = r2_score(np.exp(y_train), y_pred_train)\n","mape_train = metrics.mean_absolute_percentage_error(np.exp(y_train), y_pred_train)\n","\n","metrics_dict = {\n","    'Test': [mse, mape, r2],\n","    'Train': [mse_train, mape_train, r2_train]\n","}\n","\n","\n","\n","pd.DataFrame(metrics_dict, index=['MSE', 'MAPE', 'R2'])\n"],"metadata":{"id":"e1KVQu-CnHsI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Adding FeatureSelection"],"metadata":{"id":"b-cNmYB_nV0c"}},{"cell_type":"code","source":["# Define categorical and numerical features\n","categorical_features = ['cut', 'color', 'clarity']\n","numerical_features = ['carat', 'depth', 'table', 'x', 'y', 'z']\n","\n","# Define transformations for numerical features\n","num_transformers = ColumnTransformer(\n","    transformers=[\n","        ('xyz_transform', Pipeline([\n","            ('log', FunctionTransformer(np.log1p, validate=True)),\n","            ('scaler', StandardScaler())\n","        ]), ['x', 'y', 'z']),\n","        ('carat_scaler', Pipeline([\n","            ('log', FunctionTransformer(np.log, validate=True)),\n","            ('scaler', StandardScaler())\n","        ]), ['carat']),\n","        ('depth_transform', StandardScaler(), ['depth']),\n","        ('table_scaler', StandardScaler(), ['table']),\n","    ]\n",")\n","\n","# Feature selection\n","feature_selector = SelectKBest(score_func=f_regression, k=8)  # Selecting best 8 features\n","\n","# Preprocessing pipeline\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', num_transformers, numerical_features),\n","        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n","    ]\n",")\n","\n","# Define model pipeline\n","pipeline = Pipeline([\n","    ('preprocessor', preprocessor),\n","    ('feature_selection', feature_selector),\n","    ('regressor', LinearRegression())\n","])\n","\n","# Split dataset\n","X = df.drop(columns=['price'])\n","y = np.log(df['price']) # Apply log transformation to target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train model\n","pipeline.fit(X_train, y_train)\n","\n","\n","\n","# Predictions\n","y_pred = np.exp(pipeline.predict(X_test)) # Reverse log transformation\n","\n","\n","# Model evaluation\n","mse = mean_squared_error(np.exp(y_test), y_pred)  # Compare in original scale\n","r2 = r2_score(np.exp(y_test), y_pred)\n","mape = metrics.mean_absolute_percentage_error(np.exp(y_test), y_pred)\n","\n","### TRAIN\n","\n","# Predictions\n","y_pred_train = np.exp(pipeline.predict(X_train)) # Reverse log transformation\n","\n","\n","# Model evaluation\n","mse_train = mean_squared_error(np.exp(y_train), y_pred_train)  # Compare in original scale\n","r2_train = r2_score(np.exp(y_train), y_pred_train)\n","mape_train = metrics.mean_absolute_percentage_error(np.exp(y_train), y_pred_train)\n","\n","metrics_dict = {\n","    'Test': [mse, mape, r2],\n","    'Train': [mse_train, mape_train, r2_train]\n","}\n","\n","\n","\n","pd.DataFrame(metrics_dict, index=['MSE', 'MAPE', 'R2'])"],"metadata":{"id":"6OdjwRU6nyh0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###❓**Exercise: Remove outliers according to scatter plots and train the model again to see whether there is improvement**"],"metadata":{"id":"4uuJXIVeqb3L"}},{"cell_type":"code","source":[],"metadata":{"id":"1BBThyS_qrAc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-fEFDfEjqq1W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###❓**Exercise: Try using OrdinalEncoder instead of OneHotEncoder - is there any change to model performance?**"],"metadata":{"id":"jQWCOMTYqrVG"}},{"cell_type":"code","source":[],"metadata":{"id":"TyvgA_bsuIeT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"knlbAj6kq1k6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Polynomial Features"],"metadata":{"id":"uPIhFEz_4VBZ"}},{"cell_type":"code","source":["from sklearn.preprocessing import PolynomialFeatures"],"metadata":{"id":"fmoaik7R4WeA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["poly_features = PolynomialFeatures(degree=2)"],"metadata":{"id":"_oL1KTlm4ngi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["poly_features.fit(X[['carat', 'x', 'y', 'z', 'table', 'depth']])"],"metadata":{"id":"O2M7wVNO4y2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["poly_features.get_feature_names_out()"],"metadata":{"id":"TMU3dIB75B55"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["poly = pd.DataFrame(poly_features.transform(X[['carat', 'x', 'y', 'z', 'table', 'depth']]), columns=poly_features.get_feature_names_out())"],"metadata":{"id":"Ot49X-bb5D9h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["poly"],"metadata":{"id":"XHeaspHw5M4S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["poly['price'] = y"],"metadata":{"id":"QYh9ZWd35XyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["poly"],"metadata":{"id":"Xa2oFu6E5g2z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["px.scatter(poly, x='x^2', y='price')"],"metadata":{"id":"wFebqNuS5jSh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ssnuvh-p5oVd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["poly.columns"],"metadata":{"id":"0o1hsR4h6ocH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_feature_target_scatter(poly, ['carat table', 'carat depth'], 'price')"],"metadata":{"id":"RvSpagjL6Cc0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VlmzgBXR6Hv4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ❓**Exercise: try adding polynomial features to diamonds, and train the model to see whether there are improvements**"],"metadata":{"id":"8a-eTUAL7emY"}},{"cell_type":"code","source":[],"metadata":{"id":"3UEXJja57kkd"},"execution_count":null,"outputs":[]}]}