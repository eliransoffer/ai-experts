{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNuR+vkUwVRpocvaTDzMWCy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import time\n","\n","# Step 1: Load Shakespeare data from TensorFlow datasets\n","path_to_file = tf.keras.utils.get_file('shakespeare.txt',\n","    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n","\n","text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n","print(f\"Length of text: {len(text)} characters\")\n","\n","# Step 2: Create vocabulary\n","vocab = sorted(set(text))\n","print(f\"{len(vocab)} unique characters\")\n","\n","char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","\n","# Vectorize the text\n","text_as_int = np.array([char2idx[c] for c in text])\n","\n","# Step 3: Create training sequences\n","seq_length = 100\n","examples_per_epoch = len(text) // (seq_length + 1)\n","\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n","sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","def split_input_target(chunk):\n","    return chunk[:-1], chunk[1:]\n","\n","dataset = sequences.map(split_input_target)\n","\n","# Shuffle and batch\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 10000\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","\n","# Step 4: Build model (stateless)\n","vocab_size = len(vocab)\n","\n","\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Input(shape=(None,)),\n","    tf.keras.layers.Embedding(vocab_size, 256),\n","    tf.keras.layers.GRU(1024, return_sequences=True),\n","    # tf.keras.layers.LSTM(200, return_sequences=True),\n","    # tf.keras.layers.LSTM(100, return_sequences=True),\n","    tf.keras.layers.Dense(vocab_size)\n","])\n","\n","model.summary()"],"metadata":{"id":"xonTe7MQR9ih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 5: Compile and train\n","\n","model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n"],"metadata":{"id":"KGw1Ld2tTPKz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(dataset, epochs=20)"],"metadata":{"id":"sgGY07POXqYI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_string = \"ROME\"\n","input_eval = [char2idx[s] for s in start_string]\n","print(input_eval)\n"],"metadata":{"id":"vOyog3HSWI19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_eval = tf.expand_dims(input_eval, 0)\n","input_eval"],"metadata":{"id":"fLxWe2TFWVow"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = model.predict(input_eval)\n","predictions.shape"],"metadata":{"id":"NRZMhDq5Wedt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = predictions[:, -1, :]  # Take last timestep\n","predictions"],"metadata":{"id":"A86SWIIpWt-r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temperature = 0.8\n","predictions = predictions / temperature"],"metadata":{"id":"dPZUKms3W89Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n","predicted_id"],"metadata":{"id":"y77EEP9EWcLT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_char = idx2char[predicted_id]\n","print(predicted_char)"],"metadata":{"id":"D1ifRnUQXEVU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 6: Text generation function\n","def generate_text(model, start_string, num_generate=500, temperature=1.0):\n","    input_eval = [char2idx[s] for s in start_string]\n","    input_eval = tf.expand_dims(input_eval, 0)\n","\n","    text_generated = []\n","\n","    for _ in range(num_generate):\n","        predictions = model(input_eval)\n","        predictions = predictions[:, -1, :]  # Take last timestep\n","        predictions = predictions / temperature\n","        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n","\n","        input_eval = tf.expand_dims([predicted_id], 0)\n","        text_generated.append(idx2char[predicted_id])\n","\n","    return start_string + ''.join(text_generated)\n","\n"],"metadata":{"id":"iK04-kXEU7wH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 7: Try it!\n","print(generate_text(model, start_string=\"ROMEO: \", temperature=0.8))"],"metadata":{"id":"mQgyiEEdVdhR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(generate_text(model, num_generate=100, start_string=\"ROME\"))"],"metadata":{"id":"CtDi8lY4YM4a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nxa_44ZMYQRO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"glXxKU1saXeY"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"03441ca7"},"source":["import plotly.express as px\n","from sklearn.manifold import TSNE\n","import pandas as pd\n","\n","# Get the embedding layer weights\n","embedding_layer = model.layers[0]\n","embedding_weights = embedding_layer.get_weights()[0]\n","\n","# Reduce dimensionality using t-SNE\n","# You might need to adjust n_components and perplexity depending on your data\n","tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n","embedding_2d = tsne.fit_transform(embedding_weights)\n","\n","# Create a pandas DataFrame for Plotly\n","df_embeddings = pd.DataFrame(embedding_2d, columns=['TSNE-1', 'TSNE-2'])\n","df_embeddings['character'] = idx2char # Add character labels\n","\n","# Create an interactive scatter plot using Plotly\n","fig = px.scatter(df_embeddings, x='TSNE-1', y='TSNE-2', text='character', title='Character Embeddings Visualization (t-SNE)')\n","fig.update_traces(textposition='top center')\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MPUTDEzbbgvk"},"execution_count":null,"outputs":[]}]}