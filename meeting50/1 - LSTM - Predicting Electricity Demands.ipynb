{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNK5KkqQUFdqV5J5VIAz7wf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"v8xhbJdEVTE9"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense"],"metadata":{"id":"J_wD0RwqU7P4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: set plotly as plotting backend for pd\n","\n","import pandas as pd\n","pd.options.plotting.backend = \"plotly\""],"metadata":{"id":"BnzE2BogXjrl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data"],"metadata":{"id":"K6y71Z7dVWh9"}},{"cell_type":"code","source":["url = \"https://storage.googleapis.com/edulabs-public-datasets/AEP_hourly.csv.zip\""],"metadata":{"id":"O0j2X_yMVRlV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(url, index_col='Datetime', parse_dates=True)"],"metadata":{"id":"huK6paZlVx-2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"A_ivK5AMV0Wk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Explore and visualize the data"],"metadata":{"id":"EFvqyBlWV-N8"}},{"cell_type":"code","source":["df.plot()"],"metadata":{"id":"_Ky-Ths4WBzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.sort_index().plot()"],"metadata":{"id":"YIaD4DxnX50q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.sort_index()"],"metadata":{"id":"8Zm0mb2tYBnz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preprocess the Data"],"metadata":{"id":"WTovnUFDWEJz"}},{"cell_type":"code","source":["# a) Normalize the data\n","# LSTMs, like many neural networks, work best when input data is scaled.\n","# We'll use MinMaxScaler to scale the demand to a range of [0, 1].\n","scaler = MinMaxScaler()\n","scaled_demand = scaler.fit_transform(df)"],"metadata":{"id":"kHdwO0K1WOvH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# b) Create sequences using a sliding window\n","# We need to transform our flat time series into input sequences (X) and\n","# corresponding output labels (y).\n","def create_sequences(data, sequence_length):\n","    \"\"\"\n","    Creates input/output sequences for the LSTM.\n","    \"\"\"\n","    X, y = [], []\n","    for i in range(len(data) - sequence_length):\n","        # The input is a sequence of 'sequence_length' days\n","        X.append(data[i:(i + sequence_length), 0])\n","        # The output is the demand on the day immediately after the sequence\n","        y.append(data[i + sequence_length, 0])\n","    return np.array(X), np.array(y)\n"],"metadata":{"id":"oZdrIUnGW3IX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the sequence length\n","SEQUENCE_LENGTH = 24\n","\n","X, y = create_sequences(scaled_demand, SEQUENCE_LENGTH)\n","\n","# Reshape X to be [samples, time_steps, features] which is required by LSTM layers\n","X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n","print(f\"Shape of X: {X.shape}\")\n","print(f\"Shape of y: {y.shape}\")"],"metadata":{"id":"FYK-2e8CXEoh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","# --- 5. Split Data into Training and Testing Sets ---\n","# We'll use the first 80% of the data for training and the last 20% for testing.\n","# It's crucial not to shuffle time-series data.\n","train_size = int(len(X) * 0.8)\n","X_train, X_test = X[:train_size], X[train_size:]\n","y_train, y_test = y[:train_size], y[train_size:]\n","\n","print(f\"Training samples: {len(X_train)}\")\n","print(f\"Testing samples: {len(X_test)}\")"],"metadata":{"id":"1MwZY2RMYPXI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Basic LSTM Model"],"metadata":{"id":"TZZBPSYYYS15"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AZICACvBTnj5"},"outputs":[],"source":["# --- 6. Build the LSTM Model ---\n","# We'll create a simple LSTM model with one LSTM layer and one Dense output layer.\n","model = Sequential([\n","    tf.keras.layers.Input(shape=(SEQUENCE_LENGTH, 1)),\n","    LSTM(units=50, return_sequences=False),\n","    Dense(units=1)\n","])\n","\n","model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n","\n","model.summary()\n"]},{"cell_type":"code","source":["# --- 7. Train the Model ---\n","\n","history = model.fit(\n","    X_train,\n","    y_train,\n","    epochs=2,\n","    batch_size=32,\n","    validation_split=0.1, # Use 10% of training data for validation\n","    verbose=1\n",")"],"metadata":{"id":"xmDZDKoCYpZ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot training & validation loss\n","plt.figure(figsize=(12, 6))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Model Loss During Training')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss (MSE)')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"79Qk1296ZUk6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 8. Evaluate the Model and Make Predictions ---\n","\n","# Make predictions on the test set\n","predicted_demand_scaled = model.predict(X_test)\n","\n","# Inverse transform the predictions and actual values to their original scale\n","predicted_demand = scaler.inverse_transform(predicted_demand_scaled)\n","y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n","\n","# Calculate Root Mean Squared Error (RMSE)\n","rmse = np.sqrt(mean_squared_error(y_test_actual, predicted_demand))\n","print(f\"Root Mean Squared Error (RMSE) on Test Set: {rmse:.2f}\")\n","\n","\n"],"metadata":{"id":"FX82ZqI6YiFe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: visualize results with plotly\n","\n","import pandas as pd\n","import plotly.express as px\n","\n","# --- 9. Visualize the Results with Plotly ---\n","# Plot the actual vs. predicted values for the test set using Plotly.\n","\n","# Create a DataFrame for easy plotting\n","results_df = pd.DataFrame({\n","    'Actual Demand': y_test_actual.flatten(),\n","    'Predicted Demand': predicted_demand.flatten()\n","}, index=df.index[-len(y_test_actual):])\n","\n","fig = px.line(results_df, title='Electricity Demand: Actual vs. Predicted (Plotly)')\n","fig.update_layout(\n","    xaxis_title='Date',\n","    yaxis_title='Demand (MW)'\n",")\n","fig.show()\n","\n","# Visualize training & validation loss with Plotly\n","loss_history_df = pd.DataFrame({\n","    'Training Loss': history.history['loss'],\n","    'Validation Loss': history.history['val_loss']\n","})\n","\n","fig_loss = px.line(loss_history_df, title='Model Loss During Training (Plotly)')\n","fig_loss.update_layout(\n","    xaxis_title='Epoch',\n","    yaxis_title='Loss (MSE)'\n",")\n","fig_loss.show()"],"metadata":{"id":"R8Z4wYNEaFq-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Multiple LSTM Layers"],"metadata":{"id":"uzQWjPElZncd"}},{"cell_type":"code","source":[],"metadata":{"id":"RH2jiBlkZp3F"},"execution_count":null,"outputs":[]}]}