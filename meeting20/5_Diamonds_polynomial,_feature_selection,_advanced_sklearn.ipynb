{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and configurations"
      ],
      "metadata": {
        "id": "nRwlfYGNRiAc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwkbQ-fIRL68"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from math import sqrt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "#  (high-level, simple to use)\n",
        "import plotly.express as px\n",
        "# (low-level, highly customizable)\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from scipy import stats\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Plotly as Pandas plotting backend\n",
        "\n",
        "pd.options.plotting.backend = \"plotly\"\n",
        "np.set_printoptions(precision=2, suppress=True)\n",
        "pd.options.display.precision = 2\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "# pd.options.display.max_columns\n"
      ],
      "metadata": {
        "id": "e8YiTxWdNV80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "vrigoF3iSGUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset('diamonds')"
      ],
      "metadata": {
        "id": "DIo_DKZhSFyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced sklearn\n"
      ],
      "metadata": {
        "id": "Uj1kC5tNTB6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding FeatureSelection"
      ],
      "metadata": {
        "id": "b-cNmYB_nV0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define categorical and numerical features\n",
        "categorical_features = ['cut', 'color', 'clarity']\n",
        "numerical_features = ['carat', 'depth', 'table', 'x', 'y', 'z']\n",
        "\n",
        "# Define transformations for numerical features\n",
        "num_transformers = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('xyz_transform', Pipeline([\n",
        "            ('log', FunctionTransformer(np.log1p, validate=True)),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), ['x', 'y', 'z']),\n",
        "        ('carat_scaler', Pipeline([\n",
        "            ('log', FunctionTransformer(np.log, validate=True)),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), ['carat']),\n",
        "        ('depth_transform', StandardScaler(), ['depth']),\n",
        "        ('table_scaler', StandardScaler(), ['table']),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Feature selection\n",
        "feature_selector = SelectKBest(score_func=f_regression, k=5)  # Selecting best 8 features\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', num_transformers, numerical_features),\n",
        "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define model pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('feature_selection', feature_selector),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Split dataset\n",
        "X = df.drop(columns=['price'])\n",
        "y = np.log(df['price']) # Apply log transformation to target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# Predictions\n",
        "y_pred = np.exp(pipeline.predict(X_test)) # Reverse log transformation\n",
        "\n",
        "\n",
        "# Model evaluation\n",
        "mse = mean_squared_error(np.exp(y_test), y_pred)  # Compare in original scale\n",
        "r2 = r2_score(np.exp(y_test), y_pred)\n",
        "mape = metrics.mean_absolute_percentage_error(np.exp(y_test), y_pred)\n",
        "\n",
        "### TRAIN\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = np.exp(pipeline.predict(X_train)) # Reverse log transformation\n",
        "\n",
        "\n",
        "# Model evaluation\n",
        "mse_train = mean_squared_error(np.exp(y_train), y_pred_train)  # Compare in original scale\n",
        "r2_train = r2_score(np.exp(y_train), y_pred_train)\n",
        "mape_train = metrics.mean_absolute_percentage_error(np.exp(y_train), y_pred_train)\n",
        "\n",
        "metrics_dict = {\n",
        "    'Test': [mse, mape, r2],\n",
        "    'Train': [mse_train, mape_train, r2_train]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "pd.DataFrame(metrics_dict, index=['MSE', 'MAPE', 'R2'])"
      ],
      "metadata": {
        "id": "6OdjwRU6nyh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynomial Features"
      ],
      "metadata": {
        "id": "uPIhFEz_4VBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "metadata": {
        "id": "fmoaik7R4WeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_features = PolynomialFeatures(degree=2)"
      ],
      "metadata": {
        "id": "_oL1KTlm4ngi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_features.fit(X[['carat', 'x', 'y', 'z', 'table', 'depth']])"
      ],
      "metadata": {
        "id": "O2M7wVNO4y2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_features.get_feature_names_out()"
      ],
      "metadata": {
        "id": "TMU3dIB75B55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = pd.DataFrame(poly_features.transform(X[['carat', 'x', 'y', 'z', 'table', 'depth']]), columns=poly_features.get_feature_names_out())"
      ],
      "metadata": {
        "id": "Ot49X-bb5D9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly"
      ],
      "metadata": {
        "id": "XHeaspHw5M4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly['price'] = y"
      ],
      "metadata": {
        "id": "QYh9ZWd35XyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly"
      ],
      "metadata": {
        "id": "Xa2oFu6E5g2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.scatter(poly, x='x', y='price')"
      ],
      "metadata": {
        "id": "b_UTFseEnrrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.scatter(poly, x='x^2', y='price')"
      ],
      "metadata": {
        "id": "wFebqNuS5jSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.scatter(poly, x='x y', y='price')"
      ],
      "metadata": {
        "id": "ZScM3LFjnv-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.scatter(poly, x='carat table', y='price')"
      ],
      "metadata": {
        "id": "tULEpk_eniM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùì**Exercise: try adding polynomial features to diamonds, and train the model to see whether there are improvements**\n",
        "\n",
        "- try order 2 and 3\n",
        "- try playing with interactions_only (True/False)\n",
        "- use pipelines and FeatureSelection to see whether you can improve the results"
      ],
      "metadata": {
        "id": "8a-eTUAL7emY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3UEXJja57kkd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}