{"cells":[{"cell_type":"markdown","id":"9d60aced","metadata":{"id":"9d60aced"},"source":["# 🏠 Washington Housing Regression Task\n","\n","In this exercise, you'll build several regression models to predict housing prices using the Washington housing dataset.\n","You'll explore different algorithms, evaluate their performance, and determine which model works best."]},{"cell_type":"markdown","id":"ba55d4d7","metadata":{"id":"ba55d4d7"},"source":["### 📘 Step 1: Load the Dataset\n","Use the dataset provided via URL. Load it into a Pandas DataFrame and display the first few rows."]},{"cell_type":"code","execution_count":null,"id":"0f286c3d","metadata":{"id":"0f286c3d"},"outputs":[],"source":["# Load dataset here\n","import pandas as pd\n","data_path = \"https://storage.googleapis.com/edulabs-public-datasets/housing_washington.csv\"\n","# df = pd.read_csv('YOUR_DATASET_URL_HERE')"]},{"cell_type":"markdown","id":"5edb2375","metadata":{"id":"5edb2375"},"source":["### 📘 Step 2: Explore and Clean the Data\n","Check for null values, understand data types, and decide on appropriate cleaning strategies."]},{"cell_type":"code","execution_count":null,"id":"4544e6d8","metadata":{"id":"4544e6d8"},"outputs":[],"source":["# Explore and clean the dataset"]},{"cell_type":"markdown","id":"cca1981a","metadata":{"id":"cca1981a"},"source":["### 📘 Step 3: Preprocess the Data\n","Convert categorical columns to numeric (if needed), scale/normalize features, define `X` and `y`."]},{"cell_type":"code","execution_count":null,"id":"11e7a9c0","metadata":{"id":"11e7a9c0"},"outputs":[],"source":["# Preprocessing, feature encoding, etc."]},{"cell_type":"markdown","id":"ad575a04","metadata":{"id":"ad575a04"},"source":["### 📘 Step 4: Train-Test Split\n","Split the dataset into train and test sets (e.g., 80/20)."]},{"cell_type":"code","execution_count":null,"id":"5fe86f6b","metadata":{"id":"5fe86f6b"},"outputs":[],"source":["# from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","id":"1181754b","metadata":{"id":"1181754b"},"source":["### 📘 Step 5: Linear Regression\n","Train a linear regression model and evaluate using R² and MAE."]},{"cell_type":"code","execution_count":null,"id":"068512ba","metadata":{"id":"068512ba"},"outputs":[],"source":["# from sklearn.linear_model import LinearRegression"]},{"cell_type":"markdown","id":"660eef35","metadata":{"id":"660eef35"},"source":["### 📘 Step 6: Decision Tree Regressor\n","Train and evaluate a decision tree regressor. Tune depth if necessary."]},{"cell_type":"code","execution_count":null,"id":"dc687bde","metadata":{"id":"dc687bde"},"outputs":[],"source":["# from sklearn.tree import DecisionTreeRegressor"]},{"cell_type":"markdown","id":"9a95104d","metadata":{"id":"9a95104d"},"source":["### 📘 Step 7: K-Nearest Neighbors\n","Train and evaluate a KNN regressor. Try different `k` values."]},{"cell_type":"code","execution_count":null,"id":"2b443beb","metadata":{"id":"2b443beb"},"outputs":[],"source":["# from sklearn.neighbors import KNeighborsRegressor"]},{"cell_type":"markdown","id":"6bc96710","metadata":{"id":"6bc96710"},"source":["### 📘 Step 8: Random Forest\n","Train and evaluate a Random Forest regressor."]},{"cell_type":"code","execution_count":null,"id":"2911884e","metadata":{"id":"2911884e"},"outputs":[],"source":["# from sklearn.ensemble import RandomForestRegressor"]},{"cell_type":"markdown","id":"7335c940","metadata":{"id":"7335c940"},"source":["### 📘 Step 9: Gradient Boosting (or XGBoost)\n","Train and evaluate a boosting model (either sklearn or XGBoost)."]},{"cell_type":"code","execution_count":null,"id":"a22c3c46","metadata":{"id":"a22c3c46"},"outputs":[],"source":["# from sklearn.ensemble import GradientBoostingRegressor or import xgboost as xgb"]},{"cell_type":"markdown","id":"d8ccbd9b","metadata":{"id":"d8ccbd9b"},"source":["### 📘 Step 10: Voting Regressor\n","Combine multiple models into a Voting Regressor and evaluate."]},{"cell_type":"code","execution_count":null,"id":"221c381a","metadata":{"id":"221c381a"},"outputs":[],"source":["# from sklearn.ensemble import VotingRegressor"]},{"cell_type":"markdown","id":"6e7b59f1","metadata":{"id":"6e7b59f1"},"source":["### 📘 Step 11: Stacking Regressor\n","Use base models and a meta-model to train a Stacking Regressor."]},{"cell_type":"code","execution_count":null,"id":"f038676a","metadata":{"id":"f038676a"},"outputs":[],"source":["# from sklearn.ensemble import StackingRegressor"]},{"cell_type":"markdown","id":"69de4dc4","metadata":{"id":"69de4dc4"},"source":["### 📘 Step 12: Compare All Models\n","Compare all model scores (R², MAE). Summarize performance in a table."]},{"cell_type":"code","execution_count":null,"id":"1ba9eb20","metadata":{"id":"1ba9eb20"},"outputs":[],"source":["# Compare model performances"]},{"cell_type":"markdown","id":"2dff998c","metadata":{"id":"2dff998c"},"source":["### 📘 Step 13: Final Thoughts\n","Which model performed best and why? Would you trust it in production?"]},{"cell_type":"code","execution_count":null,"id":"a09725bb","metadata":{"id":"a09725bb"},"outputs":[],"source":["# Your conclusion here"]}],"metadata":{"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}